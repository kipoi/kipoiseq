{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "above-craps",
   "metadata": {},
   "source": [
    "# Prototype for a more generic dataloader interface\n",
    "\n",
    "This notebook walks through the design of creating a generic single sequence dataloader, with some notes on my understanding of the kipoiseq codebase (I make no guarantees as to the correctness of the latter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gross-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kipoiseq\n",
    "import kipoi\n",
    "import os\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import pyranges\n",
    "from collections import defaultdict\n",
    "\n",
    "from kipoiseq.dataloaders import *\n",
    "from kipoiseq.extractors import GenericMultiIntervalSeqExtractor, BaseMultiIntervalFetcher, \\\n",
    "    GTFMultiIntervalFetcher, BaseExtractor, FastaStringExtractor, SingleVariantMatcher, GenericSingleVariantMultiIntervalVCFSeqExtractor, \\\n",
    "    MultiSampleVCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-automation",
   "metadata": {},
   "source": [
    "Get some data to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "unique-killer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ExampleFiles/example_bed.fasta', <http.client.HTTPMessage at 0x150e6c9b40f0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make ExampleFile directory if it does not exist\n",
    "if not os.path.exists(\"ExampleFiles\"):\n",
    "    os.makedirs(\"ExampleFiles\")\n",
    "    \n",
    "# Download GTF\n",
    "urllib.request.urlretrieve(\"https://zenodo.org/record/1466102/files/example_files-gencode.v24.annotation_chr22.gtf?download=1\", 'ExampleFiles/chrom22.gtf')\n",
    "# Download fasta\n",
    "urllib.request.urlretrieve(\"https://zenodo.org/record/1466102/files/example_files-hg38_chr22.fa?download=1\", 'ExampleFiles/chrom22.fa')\n",
    "# Download bed\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/kipoi/kipoiseq/master/tests/data/intervals_51bp.tsv\", \"ExampleFiles/example_bed.bed\")\n",
    "# Download fasta that goes along with it\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/kipoi/kipoiseq/master/tests/data/hg38_chr22_32000000_32300000.fa\", \"ExampleFiles/example_bed.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-station",
   "metadata": {},
   "source": [
    "## Introducing the GenericSingleSeqDataloader in prototype.py\n",
    "\n",
    "The GenericSingleSeqDataloader extends SampleIterator from kipoi and is composed of three main components:\n",
    "\n",
    "* An interval fetcher (of type BaseMultiIntervalFetcher from kipoiseq.extractors.multi_interval). This is a generator object that provides intervals defining the location (in some reference) of the sequences of interest. The way BaseMultiIntervalFetcher is designed is that it provides, for a given key (e.g. a transcript_id), a list of intervals (kipoiseq.datatypes.Interval) that correspond to that key (e.g. all exons of that transcript). As generator, it simply iterates through the keys and returns both keys and corresponding intervals. \n",
    "    * Currently, the main working implementation of BaseMultiIntervalFetcher is GTFMultiIntervalFetcher (from kipoiseq.extractors.gtf). This, despite the name, is not tied to gtf but only requires a pyranges-like pandas dataframe (so dataframe with at least the columns Chromosome, Start, End, Strand) - which can be delivered from other sources easily. The key is the dataframe index. If the index is not unique, then it will return all intervals that have the same index (I am not sure this is an intended functionality in pandas, but it seems to work well). \n",
    "    * One could also probably easily design a fetcher that gets intervals just in time, from a database or similar. This might be better when doing analyses on whole genomes\n",
    "* A reference sequence source, usually a FastaExtractor, which given an interval provides the corresponding reference sequence\n",
    "* A sequence transformer (e.g. OneHot), which given a string sequence provides a transformed sequence as required by a model\n",
    "\n",
    "The operation of this class is quite straightforward: it gets keys and intervals from the fetcher, extracts the sequence using the reference sequence source, transforms it, and then returns it in a dict together with metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-pencil",
   "metadata": {},
   "source": [
    "With this, I believe it is very easy to build new dataloaders for most standard use-cases. All one needs to do is:\n",
    "* Define a way to import and preprocess interval data and supply them to the Fetcher. In most cases, this will be as easy as reading in a dataframe with pyranges (from gtf, bed, tsv, ...), doing some pandas operations on it, and then calling init of the GTFMUltiIntervalFetcher (which could maybe be renamed to RangesDataFrameFetcher or something)\n",
    "* Define a way to load reference sequence data (in 99% of cases this will be a fasta file supplied to a FastaSequenceExtractor)\n",
    "* Define some transformations, if necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-schedule",
   "metadata": {},
   "source": [
    "## Building a gtf based TSS dataloader for Xpresso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-still",
   "metadata": {},
   "source": [
    "We can use this template to design a TSS dataloader for Xpresso:\n",
    "\n",
    "The main thing we need to write is some way to extract TSS sites from a pyranges-like dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jewish-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSSFinder:\n",
    "    \"\"\"\n",
    "    Imputes approximate TSS location as 5' end of the gene annotation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_upstream,\n",
    "        n_downstream\n",
    "    ):\n",
    "        self.n_upstream = n_upstream\n",
    "        self.n_downstream = n_downstream\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        region_df : pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        region_df = region_df.query('Feature == \"gene\" and gene_type == \"protein_coding\"')\n",
    "        anchor = ((region_df.Start * (region_df.Strand == \"+\")) \n",
    "                  + (region_df.End * (region_df.Strand == \"-\")))\n",
    "        region_df[\"Start\"] = (anchor + \n",
    "                (-self.n_upstream * (region_df.Strand == \"+\")) + \n",
    "                (-self.n_downstream * (region_df.Strand == \"-\")))\n",
    "        region_df[\"End\"] = (anchor + \n",
    "                (self.n_downstream * (region_df.Strand == \"+\")) + \n",
    "                (self.n_upstream * (region_df.Strand == \"-\")))\n",
    "        return region_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-paragraph",
   "metadata": {},
   "source": [
    "Once we have that, we can easily build a TSS Dataloader simply by extending our GenericSingleSeqDataloader and building the fetcher, extractor and transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "developing-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kipoiseq.dataloaders.prototype import GenericSingleSeqDataloader, IdentityTransform\n",
    "class TSSDataloader(GenericSingleSeqDataloader):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        gtf_file : str,\n",
    "        fasta_file : str,\n",
    "        n_upstream : int,\n",
    "        n_downstream : int,\n",
    "        interval_attrs = [\"gene_id\", \"gene_type\"]\n",
    "    ):\n",
    "        self.gtf_file = gtf_file\n",
    "        self.fasta_file = fasta_file\n",
    "        self.n_upstream = n_upstream\n",
    "        self.n_downstream = n_downstream\n",
    "        self.use_strand = True\n",
    "        \n",
    "        # Source interval data from gtf\n",
    "        df = pyranges.read_gtf(self.gtf_file).df\n",
    "        # Subset to areas of interest\n",
    "        df = TSSFinder(\n",
    "            self.n_upstream,\n",
    "            self.n_downstream\n",
    "        )(df)\n",
    "        # Build the interval fetcher\n",
    "        interval_source = GTFMultiIntervalFetcher(\n",
    "            df, \n",
    "            keep_attrs=interval_attrs\n",
    "        )\n",
    "        # Source reference sequence from fasta\n",
    "        reference_sequence_source = FastaStringExtractor(\n",
    "            fasta_file,\n",
    "            use_strand=self.use_strand\n",
    "        )\n",
    "        # Provide sequence transformer\n",
    "        sequence_transformer = IdentityTransform()\n",
    "        # Pass all to superclass\n",
    "        super().__init__(\n",
    "            interval_source,\n",
    "            reference_sequence_source,\n",
    "            sequence_transformer,\n",
    "            interval_attrs\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-suffering",
   "metadata": {},
   "source": [
    "Lets build it and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "passive-count",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/envs/kipoi-Framepool2/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/modules/i12g/anaconda/envs/kipoi-Framepool2/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "tss = TSSDataloader(\"ExampleFiles/chrom22.gtf\",\n",
    "                   \"ExampleFiles/chrom22.fa\",\n",
    "                   7000,\n",
    "                   3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "individual-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf_df = pyranges.read_gtf(\"ExampleFiles/chrom22.gtf\").df\n",
    "\n",
    "# Check that we faithfully recover the original TSS\n",
    "for sample in tss:\n",
    "    gene_id = sample[\"metadata\"][\"gene_id\"]\n",
    "    gene_strand = sample[\"metadata\"]['ranges'].strand\n",
    "    gtf_row = gtf_df.query('gene_id == @gene_id')\n",
    "    if len(gtf_row) == 0:\n",
    "        print(gene_id)\n",
    "    if gene_strand == \"+\":\n",
    "        implied_TSS = sample[\"metadata\"]['ranges'].start + 7000\n",
    "        assert(gtf_row.iloc[0].Start == implied_TSS)\n",
    "    if gene_strand == \"-\":\n",
    "        implied_TSS = sample[\"metadata\"]['ranges'].end - 7000\n",
    "        assert(gtf_row.iloc[0].End == implied_TSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-general",
   "metadata": {},
   "source": [
    "## Extracting PolyA sequences\n",
    "\n",
    "We could also extract PolyA sites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hispanic-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyAFinder:\n",
    "    \"\"\"\n",
    "    Imputes approximate polyA location as 3' end of the transcript annotation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_upstream,\n",
    "        n_downstream\n",
    "    ):\n",
    "        self.n_upstream = n_upstream\n",
    "        self.n_downstream = n_downstream\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        region_df : pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        region_df = region_df.query('Feature == \"transcript\" and transcript_type == \"protein_coding\"')\n",
    "        anchor = ((region_df.End * (region_df.Strand == \"+\")) \n",
    "                + (region_df.Start * (region_df.Strand == \"-\")))\n",
    "        region_df[\"Start\"] = (anchor + \n",
    "                (-self.n_upstream * (region_df.Strand == \"+\")) + \n",
    "                (-self.n_downstream * (region_df.Strand == \"-\")))\n",
    "        region_df[\"End\"] = (anchor + \n",
    "                (self.n_downstream * (region_df.Strand == \"+\")) + \n",
    "                (self.n_upstream * (region_df.Strand == \"-\")))\n",
    "        return region_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-technology",
   "metadata": {},
   "source": [
    "All we need to do to achieve this, is to replace the TSSFinder with a PolyAFinder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "emotional-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyADataloader(GenericSingleSeqDataloader):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        gtf_file : str,\n",
    "        fasta_file : str,\n",
    "        n_upstream : int,\n",
    "        n_downstream : int,\n",
    "        interval_attrs = [\"gene_id\", \"transcript_id\", \"transcript_type\"]\n",
    "    ):\n",
    "        self.gtf_file = gtf_file\n",
    "        self.fasta_file = fasta_file\n",
    "        self.n_upstream = n_upstream\n",
    "        self.n_downstream = n_downstream\n",
    "        self.use_strand = True\n",
    "        \n",
    "        # Source interval data from gtf\n",
    "        df = pyranges.read_gtf(self.gtf_file).df\n",
    "        # Subset to areas of interest\n",
    "        df = PolyAFinder(\n",
    "            self.n_upstream,\n",
    "            self.n_downstream\n",
    "        )(df)\n",
    "        # Build the interval fetcher\n",
    "        interval_source = GTFMultiIntervalFetcher(\n",
    "            df, \n",
    "            keep_attrs=interval_attrs\n",
    "        )\n",
    "        # Source reference sequence from fasta\n",
    "        reference_sequence_source = FastaStringExtractor(\n",
    "            fasta_file,\n",
    "            use_strand=self.use_strand\n",
    "        )\n",
    "        # Provide sequence transformer\n",
    "        sequence_transformer = IdentityTransform()\n",
    "        # Pass all to superclass\n",
    "        super().__init__(\n",
    "            interval_source,\n",
    "            reference_sequence_source,\n",
    "            sequence_transformer,\n",
    "            interval_attrs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "demanding-clear",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/envs/kipoi-Framepool2/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/modules/i12g/anaconda/envs/kipoi-Framepool2/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "polyA = PolyADataloader(\"ExampleFiles/chrom22.gtf\",\n",
    "                   \"ExampleFiles/chrom22.fa\",\n",
    "                   102,\n",
    "                   103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "purple-wholesale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': {'seq': 'TTTCTGGCATTGTCTGCCCAGCTGCTCCAAGCCAGACTGATGAAGGAGGAGTCCCCAGTGGTGAGCTGGAGGTTGGAGCCTGAAGATGGCACAGCTCTGTGATTCATCTTCTGCGGTTGTGGCAGCCACGGTGATGGAGACGGCAGCTCAACAGGAGCAATAGGAGGGTACCCATGGAGGCCAAGTGGTAGGATCCTTGGAGGGT'},\n",
       " 'metadata': {'gene_id': 'ENSG00000279973.1',\n",
       "  'transcript_id': 'ENST00000624155.1',\n",
       "  'transcript_type': 'protein_coding',\n",
       "  'ranges': GenomicRanges(chr='chr22', start=11067987, end=11068192, id=1, strand='+')}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(polyA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-evolution",
   "metadata": {},
   "source": [
    "## Sourcing data from a bed file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-solid",
   "metadata": {},
   "source": [
    "Say we already have a bed file defining the areas of interest. We can easily build a dataloader for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "mediterranean-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BEDLoader:\n",
    "    \"\"\"\n",
    "    Class that loads a bed as pyranges-like pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        bed_path : str\n",
    "    ):\n",
    "        self.bed_path = bed_path\n",
    "    \n",
    "    def load_df(self) -> pd.DataFrame:\n",
    "        df = pyranges.read_bed(self.bed_path).df\n",
    "        if \"Strand\" not in df.keys():\n",
    "            df[\"Strand\"] = \"*\"\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "uniform-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChrRename:\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        region_df\n",
    "    ):\n",
    "        region_df[\"Chromosome\"] = region_df[\"Chromosome\"].str.replace(\"^chr\", \"\")\n",
    "        return region_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-martin",
   "metadata": {},
   "source": [
    "All we need to do to achieve this is to use the BEDLoader rather than reading a GTF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "greatest-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BedDataloader(GenericSingleSeqDataloader):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        bed_file : str,\n",
    "        fasta_file : str,\n",
    "        use_strand : bool,\n",
    "        interval_attrs = [\"Name\"]\n",
    "    ):\n",
    "        self.bed_file = bed_file\n",
    "        self.fasta_file = fasta_file\n",
    "        self.use_strand = use_strand\n",
    "        \n",
    "        # Source interval data from bed\n",
    "        df = BEDLoader(self.bed_file).load_df()\n",
    "        #df = ChrRename()(df)\n",
    "        # Build the interval fetcher iterator\n",
    "        interval_source = GTFMultiIntervalFetcher(\n",
    "            df, \n",
    "            keep_attrs=interval_attrs\n",
    "        )\n",
    "        # Source reference sequence from fasta\n",
    "        reference_sequence_source = FastaStringExtractor(\n",
    "            fasta_file,\n",
    "            use_strand=self.use_strand\n",
    "        )\n",
    "        # Provide sequence transformer\n",
    "        sequence_transformer = IdentityTransform()\n",
    "        # Pass all to superclass\n",
    "        super().__init__(\n",
    "            interval_source,\n",
    "            reference_sequence_source,\n",
    "            sequence_transformer,\n",
    "            interval_attrs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opposed-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed = BedDataloader(\"ExampleFiles/example_bed.bed\",\n",
    "                   \"ExampleFiles/example_bed.fasta\",\n",
    "                   use_strand = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-sigma",
   "metadata": {},
   "source": [
    "Test equivalence to old StringSeqDL dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "apparent-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_old = StringSeqIntervalDl(\"ExampleFiles/example_bed.bed\",\n",
    "                   \"ExampleFiles/example_bed.fasta\")\n",
    "\n",
    "seq_new = [x[\"inputs\"][\"seq\"] for x in bed]\n",
    "seq_old = [x[\"inputs\"] for x in bed_old]\n",
    "assert(x == y for x,y in zip(seq_new, seq_old))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-leisure",
   "metadata": {},
   "source": [
    "## Extracting all CDS sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-tribune",
   "metadata": {},
   "source": [
    "Exploiting this design, we can very easily also make a dataloader that works on spliced sequences, e.g. coding sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "defined-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDSFinder:\n",
    "    \"\"\"\n",
    "    Extracts CDS\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        region_df : pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        region_df = region_df.query('Feature == \"CDS\" and transcript_type == \"protein_coding\"')\n",
    "        region_df.set_index(\"transcript_id\", inplace=True)\n",
    "        return region_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cooperative-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDSDataloader(GenericSingleSeqDataloader):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        gtf_file : str,\n",
    "        fasta_file : str,\n",
    "        incl_chr = [\"chr1\"],\n",
    "        interval_attrs = [\"gene_id\", \"transcript_type\"]\n",
    "    ):\n",
    "        self.gtf_file = gtf_file\n",
    "        self.fasta_file = fasta_file\n",
    "        self.use_strand = True\n",
    "        \n",
    "        # Source interval data from gtf\n",
    "        df = (pyranges.read_gtf(self.gtf_file)\n",
    "              .df\n",
    "              .query('Chromosome in @incl_chr')\n",
    "             )\n",
    "        # Subset to areas of interest\n",
    "        df = CDSFinder()(df)\n",
    "        # Build the interval fetcher iterator\n",
    "        interval_source = GTFMultiIntervalFetcher(\n",
    "            df, \n",
    "            keep_attrs=interval_attrs\n",
    "        )\n",
    "        # Source reference sequence from fasta\n",
    "        reference_sequence_source = FastaStringExtractor(\n",
    "            fasta_file,\n",
    "            use_strand=self.use_strand\n",
    "        )\n",
    "        # Provide sequence transformer\n",
    "        sequence_transformer = IdentityTransform()\n",
    "        # Pass all to superclass\n",
    "        super().__init__(\n",
    "            interval_source,\n",
    "            reference_sequence_source,\n",
    "            sequence_transformer,\n",
    "            interval_attrs\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-benchmark",
   "metadata": {},
   "source": [
    "Get some test data (big files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "automatic-mauritius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ExampleFiles/mouse.fa.gz', <email.message.Message at 0x2b21fe7615c0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ground truth\n",
    "urllib.request.urlretrieve(\"ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M26/gencode.vM26.pc_transcripts.fa.gz\", \n",
    "                           \"ExampleFiles/mouse_transcripts.fa.gz\")\n",
    "# gtf\n",
    "urllib.request.urlretrieve(\"ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M26/gencode.vM26.basic.annotation.gtf.gz\", \n",
    "                           \"ExampleFiles/mouse.gtf.gz\")\n",
    "# fasta\n",
    "urllib.request.urlretrieve(\"ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M26/GRCm39.primary_assembly.genome.fa.gz\", \n",
    "                           \"ExampleFiles/mouse.fa.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-preservation",
   "metadata": {},
   "source": [
    "We have to unzip the fasta, because the kipoiseq fasta extractor is **very** slow on gzipped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "desirable-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gunzip ExampleFiles/mouse.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-place",
   "metadata": {},
   "source": [
    "PyRanges loading of big gtf is also not exactly lightning fast, but it offers a lot of flexibility in return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "needed-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds = CDSDataloader(\"ExampleFiles/mouse.gtf.gz\",\n",
    "                   \"ExampleFiles/mouse.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "perfect-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_seq = {x[\"metadata\"][\"ranges\"].id:x[\"inputs\"][\"seq\"] for x in cds}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-christian",
   "metadata": {},
   "source": [
    "We compare to the groud truth to see if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stuffed-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "import gzip\n",
    "\n",
    "with gzip.open(\"ExampleFiles/mouse_transcripts.fa.gz\", \"rt\") as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        record_id = record.id.split(\"|\")[0] \n",
    "        if record_id in cds_seq:\n",
    "            our_seq = cds_seq[record_id]\n",
    "            # We extract the ground truth CDS position\n",
    "            for x in record.id.split(\"|\"):\n",
    "                if x.startswith(\"CDS\"):\n",
    "                    cds_loc = x.split(\":\")[1].split(\"-\")\n",
    "            # For 3' end incomplete transcripts, we get the whole cds\n",
    "            if str(record.seq)[int(cds_loc[1]) - 3:int(cds_loc[1])] not in [\"TAA\", \"TGA\", \"TAG\"]:\n",
    "                true_seq = str(record.seq)[int(cds_loc[0]) - 1:int(cds_loc[1])]\n",
    "            else: # For 3' end complete transcripts, we need to exclude the stop codon\n",
    "                true_seq = str(record.seq)[int(cds_loc[0]) - 1:int(cds_loc[1]) - 3]\n",
    "            try:\n",
    "                assert(our_seq == true_seq)\n",
    "            except Exception:\n",
    "                print(record_id)\n",
    "                print(our_seq)\n",
    "                print(str(record.seq))\n",
    "                print(true_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-executive",
   "metadata": {},
   "source": [
    "# Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-shelf",
   "metadata": {},
   "source": [
    "The biggest value of kipoiseq are the classes that handle extraction and insertion of variants. These are very useful and provide many useful functions, but difficult to use/maintain because:\n",
    "* They are not easy to understand, at least for me, since there is a large number of objects (matchers, extractors, interval_queries etc...) and it is not super obvious which components are needed\n",
    "* The documentation is quite limited\n",
    "* They all are designed to work on VCF files. Especially for large applications (gnomAD etc.), other sources of variants may be preferable, such as hail, databases, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "posted-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat ExampleFiles/chrom22.fa | sed 's/>chr/>/g' > ExampleFiles/chrom22_nochr.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download vcf\n",
    "urllib.request.urlretrieve(\"http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/CEU.low_coverage.2010_09.genotypes.vcf.gz\", 'ExampleFiles/CEU.low_coverage.2010_09.genotypes.vcf.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "! tabix ExampleFiles/CEU.low_coverage.2010_09.genotypes.vcf.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-martial",
   "metadata": {},
   "source": [
    "## An alternative solution\n",
    "\n",
    "Just as we can break down the single sequence dataloading task into the three main components of fetching intervals, getting the ref sequence and then transforming, we can also break down the variant dataloading into three main steps:\n",
    "* Fetching variants belonging to a specific interval. For this we design a VariantFetcher class.\n",
    "* Defining a strategy how to insert multiple variants (all at the same time, all individually, one alt-seq per chromosome for phased data etc...). This is the ugliest object in the current design, but I am not sure how to get around it. Its interface is: given a list of intervals and corresponding variants, yield a template (e.g. list of intervals with the desired variants) to build exactly one alternative sequence\n",
    "* Inserting the variants into a reference sequence, respecting the strategy above. For this the existing VariantSeqExtractor works very well. For the time being, I have put a wrapper class around it, because the VariantSeqExtractor has two parameters (anchor and fixed_len) which it only gets at function call time rather than init time. If anything depends on setting these parameters dynamically, one could adapt the design to have an anchoring strategy as well, but for the time being I am not sure whether this is ever the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-proxy",
   "metadata": {},
   "source": [
    "In the prototype.py, I have created a prototype for a GenericVariantDataloader, which takes these components to load variants. It is very similar in design to the GenericSingleSeqDataloader, but with the additional steps detailed above. The code is commented to explain the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-potter",
   "metadata": {},
   "source": [
    "I think this template is easier to use/extend than the currently existing dataloaders. The currently existing code has a large hierarchy of specialized coupled objects (for example, there is a SingleVariantUTRDataLoader, which has a GenericSingleVariantMultiIntervalVCFSeqExtractor, which is BaseMultiIntervalVCFSeqExtractor (which in turn is a GenericMultiIntervalSeqExtractor, which in turn is a BaseMultiIntervalSeqExtractor) and it has a interval_fetcher and a variant seq extractor + a mixin that determines the insertion strategy and a \"matcher\" that as far as I can see is never used (see appendix)). Its a bit of a matryoshka doll that for me at least, took a considerable time to understand, and I think most new users will be scared away by this. It also leads to a proliferation of kind of useless classes. For example if I want to get variants from a hail table, I have to create a BaseMultiIntervalHailSeqExtractor and then use mixins to create the GenericSingleVariantMultiIntervalHailSeqExtractor and the GenericMultiVariantMultiIntervalHailSeqExtractor and so on.\n",
    "\n",
    "I believe the design I propose, by decoupling all of these things, makes it in my opinion a lot easier to design new dataloaders in a modular fashion (i.e. if I want tyo load from hail, I jsut change the fetcher). It also makes it easier to write a documentation for new users to understand how to build a dataloader, changing just the particular components they need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annual-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDSFinder:\n",
    "    \"\"\"\n",
    "    Extracts CDS\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        region_df : pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        region_df = region_df.query('Feature == \"CDS\" and transcript_type == \"protein_coding\"')\n",
    "        region_df.set_index(\"transcript_id\", inplace=True)\n",
    "        return region_df\n",
    "\n",
    "class ChrRename:\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        region_df\n",
    "    ):\n",
    "        region_df[\"Chromosome\"] = region_df[\"Chromosome\"].str.replace(\"^chr\", \"\")\n",
    "        return region_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "joined-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kipoiseq.dataloaders.prototype import GenericVariantDataloader, VCFVariantFetcher, SingleVariantStrategy,\\\n",
    "    IdentityTransform, VariantSequenceExtractor\n",
    "class CDSVariantDataloader(GenericVariantDataloader):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        gtf_file : str,\n",
    "        fasta_file : str,\n",
    "        vcf_file : str,\n",
    "        interval_attrs = [\"gene_id\", \"transcript_type\"]\n",
    "    ):\n",
    "        self.gtf_file = gtf_file\n",
    "        self.fasta_file = fasta_file\n",
    "        self.vcf_file = vcf_file\n",
    "        self.use_strand = True\n",
    "        \n",
    "        # Source interval data from gtf\n",
    "        df = pyranges.read_gtf(self.gtf_file).df\n",
    "        # Subset to areas of interest\n",
    "        df = CDSFinder()(df)\n",
    "        df = ChrRename()(df)\n",
    "        # Build the interval fetcher\n",
    "        interval_source = GTFMultiIntervalFetcher(\n",
    "            df, \n",
    "            keep_attrs=interval_attrs\n",
    "        )\n",
    "        # Source reference sequence from fasta\n",
    "        reference_sequence_source = FastaStringExtractor(\n",
    "            fasta_file,\n",
    "            use_strand=self.use_strand\n",
    "        )\n",
    "        # Source variants from vcf\n",
    "        variant_source = VCFVariantFetcher(\n",
    "            self.vcf_file\n",
    "        )\n",
    "        # Build variant sequence extractor\n",
    "        # I am not super sure what changing the anchor achieves \n",
    "        # The GenericSingleVariantMultiIntervalVCFSeqExtractor hardcodes it to 0\n",
    "        # So I set it by default to 0 too.\n",
    "        variant_sequence_extractor = VariantSequenceExtractor(\n",
    "            reference_sequence_source,\n",
    "            anchor = 0,\n",
    "            fixed_len = False\n",
    "        )\n",
    "        # Provide variants individually\n",
    "        variant_insertion_strategy = SingleVariantStrategy()\n",
    "        # Provide sequence transformer\n",
    "        sequence_transformer = IdentityTransform()\n",
    "        # Pass all to superclass\n",
    "        super().__init__(\n",
    "            interval_source,\n",
    "            variant_source,\n",
    "            variant_insertion_strategy,\n",
    "            reference_sequence_source,\n",
    "            variant_sequence_extractor,\n",
    "            sequence_transformer,\n",
    "            interval_attrs\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-lindsay",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adult-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdsvar = CDSVariantDataloader(\n",
    "    \"ExampleFiles/chrom22.gtf\",\n",
    "    \"ExampleFiles/chrom22_nochr.fa\",\n",
    "    \"ExampleFiles/CEU.low_coverage.2010_09.genotypes.vcf.gz\"\n",
    ")\n",
    "\n",
    "# Results when using the old extractor\n",
    "var_dict_new = defaultdict(dict)\n",
    "for item in cdsvar:\n",
    "    transcript_id = item[\"metadata\"][\"ranges\"].name\n",
    "    var_dict_new[transcript_id][\"ref\"] = item[\"inputs\"][\"ref_seq\"]\n",
    "    var_dict_new[transcript_id][\"alts\"] = var_dict_new[transcript_id].get(\"alts\", []) + [item[\"inputs\"][\"alt_seq\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "headed-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variants using old extractor as ground truth\n",
    "df = pyranges.read_gtf('ExampleFiles/chrom22.gtf').df\n",
    "df = CDSFinder()(df)\n",
    "df = ChrRename()(df)\n",
    "interval_source = GTFMultiIntervalFetcher(\n",
    "    df, \n",
    "    keep_attrs=[\"gene_id\"]\n",
    ")\n",
    "variant_matcher = SingleVariantMatcher(\n",
    "    \"ExampleFiles/CEU.low_coverage.2010_09.genotypes.vcf.gz\",\n",
    "    pranges=pyranges.PyRanges(\n",
    "        interval_source.df.reset_index()\n",
    "    )\n",
    ")\n",
    "reference_sequence_source = FastaStringExtractor(\n",
    "    \"ExampleFiles/chrom22_nochr.fa\",\n",
    "    use_strand=True\n",
    ")\n",
    "multi_sample_VCF = MultiSampleVCF(\"ExampleFiles/CEU.low_coverage.2010_09.genotypes.vcf.gz\")\n",
    "extractor = GenericSingleVariantMultiIntervalVCFSeqExtractor(\n",
    "            interval_fetcher=interval_source,\n",
    "            reference_seq_extractor=reference_sequence_source,\n",
    "            variant_matcher=variant_matcher,\n",
    "            multi_sample_VCF=multi_sample_VCF,\n",
    ")\n",
    "\n",
    "# Results when using the old extractor\n",
    "var_dict = defaultdict(dict)\n",
    "for transcript_id, (ref_seq, alt_seqs) in extractor.items():\n",
    "    alt_seq_list = [alt_seq[0] for alt_seq in alt_seqs]\n",
    "    if len(alt_seq_list) > 0:\n",
    "        var_dict[transcript_id][\"ref\"] = ref_seq\n",
    "        var_dict[transcript_id][\"alts\"] = alt_seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contained-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert([sorted(var_dict_new.keys()) == sorted(var_dict.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "earned-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "for transcript_id in var_dict_new.keys():\n",
    "    assert(var_dict_new[transcript_id][\"ref\"] == var_dict[transcript_id][\"ref\"])\n",
    "    assert(sorted(var_dict_new[transcript_id][\"alts\"]) == sorted(var_dict[transcript_id][\"alts\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-exhibition",
   "metadata": {},
   "source": [
    "# Drawbacks and Remaining Issues\n",
    "\n",
    "Specific issues of this new design:\n",
    "* The variant insertion strategy is a bit intimidating as it works with List[Tuple[Interval, List[Variant]]]. One could, of course, make a datatype for this. The main reason I  didnt do it is (a) I couldnt figure out how to name it (except for ListOfIntervalVariantsTuples, which isn't really much better) and (b) because lists are nice to work with and I did not want to write all the boilerplate to make an object implement the list interface\n",
    "* I dont really know what the anchor parameter of the VariantSeqExtractor really does, but if it actually makes a difference, this is a bit of a leaky abstraction since one needs to be quite familiar with class internals to set it correctly. \n",
    "\n",
    "More general issues:\n",
    "* Generalizing to multi-input or, worse, multimodal models (e.g. ones that use sequence + experimental tracks) is not entirely straightforward\n",
    "* There are complex variant events (e.g. a variant deleting a stop, causing a CDS to extend (on the spliced mRNA!) until the next stop is found), which are really hard to handle in a generic way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-retirement",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "An example of the somewhat confusing nature of the current variant objects: The GenericSingleVariantMultiIntervalVCFSeqExtractor (I love OOP names) wants a VariantMatcher, but as far as I can see, never uses it in any capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "descending-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pyranges.read_gtf('ExampleFiles/chrom22.gtf').df\n",
    "df = CDSFinder()(df)\n",
    "df = ChrRename()(df)\n",
    "interval_source = GTFMultiIntervalFetcher(\n",
    "    df, \n",
    "    keep_attrs=[\"gene_id\"]\n",
    ")\n",
    "variant_matcher = SingleVariantMatcher(\n",
    "    \"ExampleFiles/CEU.low_coverage.2010_09.genotypes.vcf.gz\",\n",
    "    pranges=pyranges.PyRanges(\n",
    "        interval_source.df.reset_index()\n",
    "    )\n",
    ")\n",
    "reference_sequence_source = FastaStringExtractor(\n",
    "    \"ExampleFiles/chrom22_nochr.fa\",\n",
    "    use_strand=True\n",
    ")\n",
    "multi_sample_VCF = MultiSampleVCF(\"ExampleFiles/CEU.low_coverage.2010_09.genotypes.vcf.gz\")\n",
    "extractor = GenericSingleVariantMultiIntervalVCFSeqExtractor(\n",
    "            interval_fetcher=interval_source,\n",
    "            reference_seq_extractor=reference_sequence_source,\n",
    "            variant_matcher=variant_matcher,\n",
    "            multi_sample_VCF=multi_sample_VCF,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "above-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results when using the matcher\n",
    "var_dict = defaultdict(list)\n",
    "for transcript_id, (ref_seq, alt_seqs) in extractor.items():\n",
    "    alt_seq_list = [alt_seq for alt_seq in alt_seqs]\n",
    "    for alt_seq in alt_seq_list: \n",
    "        alt_seq[1][\"source\"] = None # because cyvcf variant objects are incomparable\n",
    "    if len(alt_seq_list) > 0:\n",
    "        var_dict[transcript_id].append((ref_seq, alt_seq_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fitted-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = GenericSingleVariantMultiIntervalVCFSeqExtractor(\n",
    "            interval_fetcher=interval_source,\n",
    "            reference_seq_extractor=reference_sequence_source,\n",
    "            variant_matcher=None,\n",
    "            multi_sample_VCF=multi_sample_VCF,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dressed-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results when matcher is none\n",
    "var_dict_nomatcher = defaultdict(list)\n",
    "for transcript_id, (ref_seq, alt_seqs) in extractor.items():\n",
    "    alt_seq_list = [alt_seq for alt_seq in alt_seqs]\n",
    "    for alt_seq in alt_seq_list: \n",
    "        alt_seq[1][\"source\"] = None # because cyvcf variant objects are incomparable\n",
    "    if len(alt_seq_list) > 0:\n",
    "        var_dict_nomatcher[transcript_id].append((ref_seq, alt_seq_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "stretch-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(var_dict.keys() == var_dict_nomatcher.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "regulated-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in var_dict.keys():\n",
    "    try:\n",
    "        assert(var_dict[key] == var_dict_nomatcher[key])\n",
    "    except Exception:\n",
    "        a = var_dict[key]\n",
    "        b = var_dict_nomatcher[key]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "african-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = var_dict[next(iter(var_dict))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "psychological-monday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ATGGTGGCTGAGGCTGGTTCAATGCCGGCTGCCTCCTCTGTGAAGAAGCCATTTGGTCTCAGAAGCAAGATGGGCAAGTGGTGCCGCCACTGCTTCGCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGACTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAACTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAACAAAGTGGGCCCTTGGGGAGACTACGACGACAGCGCTTTCATGGAGCCGAGGTACCACGTCCGTCGAGAAGATCTGGACAAGCTCCACAGAGCTGCCTGGTGGGGTAAAGTCCCCAGAAAGGATCTCATCGTCATGCTCAAGGACACTGACATGAACAAGAAGGACAAGCAAAAGAGGACTGCTCTACATCTGGCCTCTGCCAATGGAAATTCAGAAGTAGTAAAACTCCTGCTGGACAGACGATGTCAACTTAATATCCTTGACAACAAAAAGAGGACAGCTCTGACAAAGGCCGTACAATGCCAGGAAGATGAATGTGCGTTAATGTTGCTGGAACATGGCACTGATCCGAATATTCCAGATGAGTATGGAAATACCGCTCTACACTATGCTATCTACAATGAAGATAAATTAATGGCCAAAGCACTGCTCTTATACGGTGCTGATATCGAATCAAAAAACAAGCATGGCCTCACACCACTGTTACTTGGTGTACATGAGCAAAAACAGCAAGTGGTGAAATTTTTAATCAAGAAAAAAGCAAATTTAAATGCACTGGATAGATATGGAAGAACTGCTCTCATACTTGCTGTATGTTGTGGATCGGCAAGTATAGTCAGCCTTCTACTTGAGCAAAACATTGATGTATCTTCTCAAGATCTATCTGGACAGACGGCCAGAGAGTATGCTGTTTCTAGTCGTCATAATGTAATTTGCCAGTTACTTTCTGACTACAAAGAAAAACAGATACTAAAAGTCTCTTCTGAAAACAGCAATCCAGAACAAGACTTAAAGCTGACATCAGAGGAAGAGTCACAAAGGCTTAAAGGAAGTGAAAATAGCCAGCCAGAGGAAATGTCTCAAGAACCAGAAATAAATAAGGGTGGTGATAGAAAGGTTGAAGAAGAAATGAAGAAGCACGGAAGTACTCATATGGGATTCCCAGAAAACCTGACTAACGGTGCCACTGCTGACAATGGTGATGATGGATTAATTCCACCAAGGAAAAGCAGAACACCTGAAAGCCAGCAATTTCCTGACACTGAGAATGAACAGTATCACAGTGATGAACAAAATGATACTCAGAAGCAACTTTCTGAAGAACAGAACACTGGAATATTACAAGATGAGATTCTGATTCATGAAGAAAAGCAGATAGAAGTGGCTGAAAATGAATTC',\n",
       "  {'chrom': '22',\n",
       "   'pos': 15690488,\n",
       "   'ref': 'T',\n",
       "   'alt': 'C',\n",
       "   'id': 'rs175148',\n",
       "   'qual': None,\n",
       "   'filter': None,\n",
       "   'info': {'AA': 'T',\n",
       "    'AC': 72,\n",
       "    'AN': 120,\n",
       "    'DP': 285,\n",
       "    'HM2': True,\n",
       "    'HM3': True,\n",
       "    'GP': '22:17310488',\n",
       "    'BN': 79},\n",
       "   'source': None}),\n",
       " ('ATGGTGGCTGAGGCTGGTTCAATGCCGGCTGCCTCCTCTGTGAAGAAGCCATTTGGTCTCAGAAGCAAGATGGGCAAGTGGTGCCGCCACTGCTTCGCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGACTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAACAAAGTGGGCCCTTGGGGAGACTACGACGACAGCGCTTTCATGGAGCCGAGGTACCACGTCCGTCGAGAAGATCTGGACAAGCTCCACAGAGCTGCCTGGTGGGGTAAAGTCCCCAGAAAGGATCTCATCGTCATGCTCAAGGACACTGACATGAACAAGAAGGACAAGCAAAAGAGGACTGCTCTACATCTGGCCTCTGCCAATGGAAATTCAGAAGTAGTAAAACTCCTGCTGGACAGACGATGTCAACTTAATATCCTTGAGAACAAAAAGAGGACAGCTCTGACAAAGGCCGTACAATGCCAGGAAGATGAATGTGCGTTAATGTTGCTGGAACATGGCACTGATCCGAATATTCCAGATGAGTATGGAAATACCGCTCTACACTATGCTATCTACAATGAAGATAAATTAATGGCCAAAGCACTGCTCTTATACGGTGCTGATATCGAATCAAAAAACAAGCATGGCCTCACACCACTGTTACTTGGTGTACATGAGCAAAAACAGCAAGTGGTGAAATTTTTAATCAAGAAAAAAGCAAATTTAAATGCACTGGATAGATATGGAAGAACTGCTCTCATACTTGCTGTATGTTGTGGATCGGCAAGTATAGTCAGCCTTCTACTTGAGCAAAACATTGATGTATCTTCTCAAGATCTATCTGGACAGACGGCCAGAGAGTATGCTGTTTCTAGTCGTCATAATGTAATTTGCCAGTTACTTTCTGACTACAAAGAAAAACAGATACTAAAAGTCTCTTCTGAAAACAGCAATCCAGAACAAGACTTAAAGCTGACATCAGAGGAAGAGTCACAAAGGCTTAAAGGAAGTGAAAATAGCCAGCCAGAGGAAATGTCTCAAGAACCAGAAATAAATAAGGGTGGTGATAGAAAGGTTGAAGAAGAAATGAAGAAGCACGGAAGTACTCATATGGGATTCCCAGAAAACCTGACTAACGGTGCCACTGCTGACAATGGTGATGATGGATTAATTCCACCAAGGAAAAGCAGAACACCTGAAAGCCAGCAATTTCCTGACACTGAGAATGAACAGTATCACAGTGATGAACAAAATGATACTCAGAAGCAACTTTCTGAAGAACAGAACACTGGAATATTACAAGATGAGATTCTGATTCATGAAGAAAAGCAGATAGAAGTGGCTGAAAATGAATTC',\n",
       "  {'chrom': '22',\n",
       "   'pos': 15695458,\n",
       "   'ref': 'T',\n",
       "   'alt': 'G',\n",
       "   'id': 'rs165652',\n",
       "   'qual': None,\n",
       "   'filter': None,\n",
       "   'info': {'AA': 'T',\n",
       "    'AC': 92,\n",
       "    'AN': 120,\n",
       "    'DP': 288,\n",
       "    'HM2': True,\n",
       "    'HM3': True,\n",
       "    'GP': '22:17315458',\n",
       "    'BN': 79},\n",
       "   'source': None}),\n",
       " ('ATGGTGGCTGAGGCTGGTTCAATGCCGGCTGCCTCCTCTGTGAAGAAGCCATTTGGTCTCAGAAGCAAGATGGGCAAGTGGTGCCGCCACTGCTTCGCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGACTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAACAAAGTGGGCCCTTGGGGAGACTACGACGACAGCGCTTTCATGGAGCCGAGGTACCACGTCCGTCGAGAAGATCTGGACAAGCTCCACAGAGCTGCCTGGTGGGGTAAAGTCCCCAGAAAGGATCTCATCGTCATGCTCAAGGACACTGACATGAACAAGAAGGACAAGCAAAAGAGGACTGCTCTACATCTGGCCTCTGCCAATGGAAATTCAGAAGTAGTAAAACTCCTGCTGGACAGACGATGTCAACTTAATATCCTTGACAACAAAAAGAGGACAGCTCTGACAAAGGCCGTACAATGCCAGGAAGATGAATGTGCGTTAATGTTGCTGGAACATGGCACTGATCCGAATATTCCAGATGAGTATGGAAATACCGCTCTACACTATGCTATCTACAATGAAGATAAATTAATGGCCAAAGCACTGCTCTTATACGGTGCTGATATCGAATCAAAAAACAAGCATGGCCTCACACCACTGTTTCTTGGTGTACATGAGCAAAAACAGCAAGTGGTGAAATTTTTAATCAAGAAAAAAGCAAATTTAAATGCACTGGATAGATATGGAAGAACTGCTCTCATACTTGCTGTATGTTGTGGATCGGCAAGTATAGTCAGCCTTCTACTTGAGCAAAACATTGATGTATCTTCTCAAGATCTATCTGGACAGACGGCCAGAGAGTATGCTGTTTCTAGTCGTCATAATGTAATTTGCCAGTTACTTTCTGACTACAAAGAAAAACAGATACTAAAAGTCTCTTCTGAAAACAGCAATCCAGAACAAGACTTAAAGCTGACATCAGAGGAAGAGTCACAAAGGCTTAAAGGAAGTGAAAATAGCCAGCCAGAGGAAATGTCTCAAGAACCAGAAATAAATAAGGGTGGTGATAGAAAGGTTGAAGAAGAAATGAAGAAGCACGGAAGTACTCATATGGGATTCCCAGAAAACCTGACTAACGGTGCCACTGCTGACAATGGTGATGATGGATTAATTCCACCAAGGAAAAGCAGAACACCTGAAAGCCAGCAATTTCCTGACACTGAGAATGAACAGTATCACAGTGATGAACAAAATGATACTCAGAAGCAACTTTCTGAAGAACAGAACACTGGAATATTACAAGATGAGATTCTGATTCATGAAGAAAAGCAGATAGAAGTGGCTGAAAATGAATTC',\n",
       "  {'chrom': '22',\n",
       "   'pos': 15698682,\n",
       "   'ref': 'C',\n",
       "   'alt': 'T',\n",
       "   'id': 'rs165670',\n",
       "   'qual': None,\n",
       "   'filter': None,\n",
       "   'info': {'AA': 'c',\n",
       "    'AC': 67,\n",
       "    'AN': 120,\n",
       "    'DP': 293,\n",
       "    'HM2': True,\n",
       "    'HM3': True,\n",
       "    'GP': '22:17318682',\n",
       "    'BN': 79},\n",
       "   'source': None}),\n",
       " ('ATGGTGGCTGAGGCTGGTTCAATGCCGGCTGCCTCCTCTGTGAAGAAGCCATTTGGTCTCAGAAGCAAGATGGGCAAGTGGTGCCGCCACTGCTTCGCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGACTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAACAAAGTGGGCCCTTGGGGAGACTACGACGACAGCGCTTTCATGGAGCCGAGGTACCACGTCCGTCGAGAAGATCTGGACAAGCTCCACAGAGCTGCCTGGTGGGGTAAAGTCCCCAGAAAGGATCTCATCGTCATGCTCAAGGACACTGACATGAACAAGAAGGACAAGCAAAAGAGGACTGCTCTACATCTGGCCTCTGCCAATGGAAATTCAGAAGTAGTAAAACTCCTGCTGGACAGACGATGTCAACTTAATATCCTTGACAACAAAAAGAGGACAGCTCTGACAAAGGCCGTACAATGCCAGGAAGATGAATGTGCGTTAATGTTGCTGGAACATGGCACTGATCCGAATATTCCAGATGAGTATGGAAATACCGCTCTACACTATGCTATCTACAATGAAGATAAATTAATGGCCAAAGCACTGCTCTTATACGGTGCTGATATCGAATCAAAAAACAAGCATGGCCTCACACCACTGTTACTTGGTGTACATGAGCAAAAACAGCAAGTGGTGAAATTTTTAATCAAGAAAAAAGCAAATTTAAATGCACTGGATAGATATGGAAGAACTGCTCTCATACTTGCTGTATGTTGTGGATCGGCAAGTATAGTCAGCCTTCTACTTGAGCAAAACATTGATGTATCTTCTCAAGATCTATCTGGACAGACGGCCAGAGAGTATGCTGTTTCTAGTCGTCATAATGTAATTTGCCAGTTACTTTCTGACTACAAAGAAAAACAGATACTAAAAGTCTCTTCTGAAAACAGCAATCCAGAACAAGACTTAAAGCTGACATCAGAGGAAGAGTCACAAAGGCTTAAAGGAAGTGAAAATAGCCAGCCAGAGGAAATGTCTCAAGAACCAGAAATAAATAAGGGTGGTGATAGAAAGGTTGAAGAAGAAATGAAGAAGCACGGAAGTACTCATATGGGATTCCCAGAAAACCTGACTAACGGTGCCACTGCTGACAATGGTGATGATGGATTAATTCCACCAAGGAAAAGCAGAACACCTGAAAGCCAGCAATTTCCTGACACTGAGAAGGAACAGTATCACAGTGATGAACAAAATGATACTCAGAAGCAACTTTCTGAAGAACAGAACACTGGAATATTACAAGATGAGATTCTGATTCATGAAGAAAAGCAGATAGAAGTGGCTGAAAATGAATTC',\n",
       "  {'chrom': '22',\n",
       "   'pos': 15711020,\n",
       "   'ref': 'A',\n",
       "   'alt': 'G',\n",
       "   'id': 'rs12483904',\n",
       "   'qual': None,\n",
       "   'filter': None,\n",
       "   'info': {'AA': 'a',\n",
       "    'AC': 28,\n",
       "    'AN': 120,\n",
       "    'DP': 268,\n",
       "    'HM2': True,\n",
       "    'GP': '22:17331020',\n",
       "    'BN': 120},\n",
       "   'source': None}),\n",
       " ('ATGGTGGCTGAGGCTGGTTCAATGCCGGCTGCCTCCTCTGTGAAGAAGCCATTTGGTCTCAGAAGCAAGATGGGCAAGTGGTGCCGCCACTGCTTCGCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGACTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAACAAAGTGGGCCCTTGGGGAGACTACGACGACAGCGCTTTCATGGAGCCGAGGTACCACGTCCGTCGAGAAGATCTGGACAAGCTCCACAGAGCTGCCTGGTGGGGTAAAGTCCCCAGAAAGGATCTCATCGTCATGCTCAAGGACACTGACATGAACAAGAAGGACAAGCAAAAGAGGACTGCTCTACATCTGGCCTCTGCCAATGGAAATTCAGAAGTAGTAAAACTCCTGCTGGACAGACGATGTCAACTTAATATCCTTGACAACAAAAAGAGGACAGCTCTGACAAAGGCCGTACAATGCCAGGAAGATGAATGTGCGTTAATGTTGCTGGAACATGGCACTGATCCGAATATTCCAGATGAGTATGGAAATACCGCTCTACACTATGCTATCTACAATGAAGATAAATTAATGGCCAAAGCACTGCTCTTATACGGTGCTGATATCGAATCAAAAAACAAGCATGGCCTCACACCACTGTTACTTGGTGTACATGAGCAAAAACAGCAAGTGGTGAAATTTTTAATCAAGAAAAAAGCAAATTTAAATGCACTGGATAGATATGGAAGAACTGCTCTCATACTTGCTGTATGTTGTGGATCGGCAAGTATAGTCAGCCTTCTACTTGAGCAAAACATTGATGTATCTTCTCAAGATCTATCTGGACAGACGGCCAGAGAGTATGCTGTTTCTAGTCGTCATAATGTAATTTGCCAGTTACTTTCTGACTACAAAGAAAAACAGATACTAAAAGTCTCTTCTGAAAACAGCAATCCAGAACAAGACTTAAAGCTGACATCAGAGGAAGAGTCACAAAGGCTTAAAGGAAGTGAAAATAGCCAGCCAGAGGAAATGTCTCAAGAACCAGAAATAAATAAGGGTGGTGATAGAAAGGTTGAAGAAGAAATGAAGAAGCACGGAAGTACTCATATGGGATTCCCAGAAAACCTGACTAACGGTGCCACTGCTGACAATGGTGATGATGGATTAATTCCACCAAGGAAAAGCAGAACACCTGAAAGCCAGCAATTTCCTGACACTGAGAATGAACAGTATCACAGTGATGAACAAAATGCTACTCAGAAGCAACTTTCTGAAGAACAGAACACTGGAATATTACAAGATGAGATTCTGATTCATGAAGAAAAGCAGATAGAAGTGGCTGAAAATGAATTC',\n",
       "  {'chrom': '22',\n",
       "   'pos': 15719674,\n",
       "   'ref': 'T',\n",
       "   'alt': 'C',\n",
       "   'id': 'rs165760',\n",
       "   'qual': None,\n",
       "   'filter': None,\n",
       "   'info': {'AA': 'N',\n",
       "    'AC': 94,\n",
       "    'AN': 120,\n",
       "    'DP': 292,\n",
       "    'GP': '22:17339674',\n",
       "    'BN': 79},\n",
       "   'source': None}),\n",
       " ('ATGGTGGCTGAGGCTGGTTCAATGCCGGCTGCCTCCTCTGTGAAGAAGCCATTTGGTCTCAGAAGCAAGATGGGCAAGTGGTGCCGCCACTGCTTCGCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGGTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGATTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAGCAACGTGGGCACTTCTGGAGACCACGACGACTCTGCTATGAAGACACTCAGGAGCAAGATGGGCAAGTGGTGCTGCCACTGCTTCCCCTGCTGCAGGGGGAGCGGCAAGAACAAAGTGGGCCCTTGGGGAGACTACGACGACAGCGCTTTCATGGAGCCGAGGTACCACGTCCGTCGAGAAGATCTGGACAAGCTCCACAGAGCTGCCTGGTGGGGTAAAGTCCCCAGAAAGGATCTCATCGTCATGCTCAAGGACACTGACATGAACAAGAAGGACAAGCAAAAGAGGACTGCTCTACATCTGGCCTCTGCCAATGGAAATTCAGAAGTAGTAAAACTCCTGCTGGACAGACGATGTCAACTTAATATCCTTGACAACAAAAAGAGGACAGCTCTGACAAAGGCCGTACAATGCCAGGAAGATGAATGTGCGTTAATGTTGCTGGAACATGGCACTGATCCGAATATTCCAGATGAGTATGGAAATACCGCTCTACACTATGCTATCTACAATGAAGATAAATTAATGGCCAAAGCACTGCTCTTATACGGTGCTGATATCGAATCAAAAAACAAGCATGGCCTCACACCACTGTTACTTGGTGTACATGAGCAAAAACAGCAAGTGGTGAAATTTTTAATCAAGAAAAAAGCAAATTTAAATGCACTGGATAGATATGGAAGAACTGCTCTCATACTTGCTGTATGTTGTGGATCGGCAAGTATAGTCAGCCTTCTACTTGAGCAAAACATTGATGTATCTTCTCAAGATCTATCTGGACAGACGGCCAGAGAGTATGCTGTTTCTAGTCGTCATAATGTAATTTGCCAGTTACTTTCTGACTACAAAGAAAAACAGATACTAAAAGTCTCTTCTGAAAACAGCAATCCAGAACAAGACTTAAAGCTGACATCAGAGGAAGAGTCACAAAGGCTTAAAGGAAGTGAAAATAGCCAGCCAGAGGAAATGTCTCAAGAACCAGAAATAAATAAGGGTGGTGATAGAAAGGTTGAAGAAGAAATGAAGAAGCACGGAAGTACTCATATGGGATTCCCAGAAAACCTGACTAACGGTGCCACTGCTGACAATGGTGATGATGGATTAATTCCACCAAGGAAAAGCAGAACACCTGAAAGCCAGCAATTTCCTGACACTGAGAATGAACAGTATCACAGTGATGAACAAAATGATACTCAGAAGCAACTTTCTGAAGAACAGAACACTGGAATATTACAAGATGAGATTCTGATTCATGAAGAAAAGCAGAAAGAAGTGGCTGAAAATGAATTC',\n",
       "  {'chrom': '22',\n",
       "   'pos': 15719752,\n",
       "   'ref': 'G',\n",
       "   'alt': 'A',\n",
       "   'id': 'rs2110439',\n",
       "   'qual': None,\n",
       "   'filter': None,\n",
       "   'info': {'AA': 'g',\n",
       "    'AC': 27,\n",
       "    'AN': 120,\n",
       "    'DP': 298,\n",
       "    'GP': '22:17339752',\n",
       "    'BN': 96},\n",
       "   'source': None})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda-kipoi-Framepool2]",
   "language": "python",
   "name": "conda-env-anaconda-kipoi-Framepool2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
